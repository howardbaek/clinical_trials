---
title: "Latent Dirichlet Allocation on MeSH Terms"
author: "Jason Baik"
date: "12/30/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

I will be analyzing MeSH (Medical Subject Headings), which are terms from the [National Library of Medicine's vocabularly](http://research.library.gsu.edu/c.php?g=115556&p=753156). Each clinical trial is assigned several MeSH to characterize the trial. A question that I will be tackling is: Can we use latent dirichlet allocation to categorize these MeSH terms into different topics?   

The dataset I'll be working with is extracted from [ClinicalTrials.gov](https://clinicaltrials.gov/), "a database of privately and publicly funded clinical studies conducted around the world". I grabbed it from PostgreSQL database using the `DBI` package, which connects to [AACT](https://aact.ctti-clinicaltrials.org/), a public database that contains information from ClinicalTrials.gov. For simplicity, I wrapped the steps needed to extract data from this database in a package called [aactr](https://github.com/jasonbaik94/aactr)

```{r, include=FALSE}
library(tidyverse)
library(tidytext)
library(topicmodels)
library(RPostgreSQL)
library(DBI)
library(broom)
library(readxl)
library(tm)
theme_set(theme_light())

# Connect to PostgreSQL database
drv <- dbDriver('PostgreSQL')
con <- dbConnect(drv, 
                 dbname="aact",
                 host="aact-db.ctti-clinicaltrials.org", 
                 port=5432,
                 user=readr::read_csv("id_pw.csv")$id, 
                 password=readr::read_csv("id_pw.csv")$pw
                 )

# Import datatable of MeSH terms called browse_conditions
browse_conditions <- tbl(con, "browse_conditions") %>% 
  collect()
```

Nick Giangreco, a Columbia PhD student, introduced me to this database. Along with Nick, I contacted the administrators of this database at Duke University, Sheri Tibbs and Karen Chiswell. Thankfully, they had categorized these MeSH terms and agreed to share this with me. Below, I import, clean, and save the excel file into `tagged_mesh_terms`

```{r, warning=FALSE, message=FALSE}
# Import and clean data
tagged_mesh_terms <- read_excel("2010_tagged_mesh_and_free_text_terms.xlsx",
                                sheet = 3) %>%
  janitor::clean_names() %>% 
  select(-c(term_type, identifier)) %>% 
  mutate(term = str_to_title(term)) %>% 
  distinct()
```


Now, I want to work with only the available MeSH terms from AACT that the Duke researchers had categorized. Subsequently, I `inner_join`ed `tagged_mesh_terms` and `browse_conditions`.
```{r}
browse_conditions_filtered <- browse_conditions %>%
  select(nct_id, mesh_term) %>% 
  inner_join(tagged_mesh_terms, by = c("mesh_term" = "term")) %>% 
  select(-clinical_domain) %>% 
  distinct()
```

* 300842 rows

Around 44% of the MeSH terms in `browse_conditions` joined with `tagged_mesh_terms`. That's alot higher than I expected. Let's use these terms in our LDA algorithm and set K = 10 since `tagged_mesh_terms` has 10 unique tags (clinical domains). I'm following this [vignette from the tidytext package](https://cran.r-project.org/web/packages/tidytext/vignettes/topic_modeling.html)



```{r}
browse_conditions_filtered_counts <- browse_conditions_filtered %>% 
  count(nct_id, mesh_term, sort = TRUE) %>% 
  ungroup()

# Create DocumentTermMatrix in order to put dataset into the LDA algorithm from the topicmodels package
browse_conditions_dtm <- browse_conditions_filtered_counts %>% 
  cast_dtm(nct_id, mesh_term, n)

# This take a few minutes
topic_lda <- topicmodels::LDA(browse_conditions_dtm, k = 10, control = list(seed = 1234))

# Use the broom package to mutate beta, the probability of that term being generated from that topic.
topic_lda_tidy <- tidy(topic_lda)

# Use top_n() to find top 5 terms within each topic
top_mesh_terms <- topic_lda_tidy %>% 
    group_by(topic) %>% 
    top_n(5, beta) %>% 
    ungroup() %>% 
    arrange(topic, -beta)
```


Visualization. We look at 5 topics at a time so that the graphs fit in our window.
```{r}
# First 5 topics
top_mesh_terms %>%
  filter(topic %in% c(1:5)) %>% 
  mutate(term = reorder(term, beta)) %>% 
  ggplot(aes(term, beta, fill = term)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", nrow = 3) +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "MeSH",
       y = "Beta (Probability of MeSH being generated from topic)",
       caption = "@jsonbaik") +
  ggtitle("Distribution of MeSH (Topics 1~5)")
```

```{r}
# Next 5 topics
top_mesh_terms %>%
  filter(topic %in% c(6:10)) %>% 
  mutate(term = reorder(term, beta)) %>% 
  ggplot(aes(term, beta, fill = term)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", nrow = 3) +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "MeSH",
       y = "Beta (Probability of MeSH being generated from topic)",
       caption = "@jsonbaik") +
  ggtitle("Distribution of MeSH (Topics 6~10)")

```

Now comes the fun part: comparison between LDA's categorization of topics and Duke researchers' categorization (the ground truth)
Create a function and `map` over it.
```{r}
check_ground_truth <- function(topic_number) {
  
  topic_term <- top_mesh_terms %>% 
    filter(topic == topic_number) %>% 
    select(term) %>% 
    pull()
  
tagged_mesh_terms %>%
  filter(term %in% topic_term) %>% 
  count(clinical_domain, sort = TRUE)
}
```

```{r}
ground_truth <- map(c(1:10), check_ground_truth)
```

Problem: Some of these MeSH terms have multiple clinical domains tagged

```{r}
# For each clinical_domain, arrange terms by decreasing order of percentage_term
distribution_term <- tagged_mesh_terms %>%
  count(clinical_domain, term) %>% 
  group_by(clinical_domain) %>% 
  mutate(percentage_term = (n / sum(n)) * 100) %>% 
  arrange(clinical_domain, -percentage_term)
```

```{r}
# Top 5 terms for each clinical domain in terms of percentage_term 
top5_terms <- tagged_mesh_terms %>%
  count(clinical_domain, term) %>% 
  group_by(clinical_domain) %>% 
  mutate(percentage_term = (n / sum(n)) * 100) %>% 
  top_n(5, percentage_term) %>% 
  # Arrange percentage terms in decreasing order
  arrange(clinical_domain, -percentage_term)
```


* `top5_terms` is dominated by `oncology_general` and `oncology_specific`. Let's filter them out and graph em

```{r}
top5_terms %>% 
  filter(!(clinical_domain %in% c("oncology_general", "oncology_specific"))) %>% 
  ggplot(aes(x = term, y = percentage_term, fill = term)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~clinical_domain, nrow = 4, scales = "free")
```

```{r}
topic1_term <- top_mesh_terms %>% 
  filter(topic == 1) %>% 
  select(term) %>% 
  pull()

topic2_term <- top_mesh_terms %>% 
  filter(topic == 2) %>% 
  select(term) %>% 
  pull()

topic3_term <- top_mesh_terms %>% 
  filter(topic == 3) %>% 
  select(term) %>% 
  pull()
```

```{r}
tagged_mesh_terms %>%
  filter(term %in% topic3_term)  
```

