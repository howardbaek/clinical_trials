---
title: "tidytext Anaylsis"
author: "Jason Baik"
date: "12/2/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Load libraries and connect to PostgreSQL database 

```{r, warning=FALSE, message = FALSE}
library(tidyverse)
library(tidytext)
library(topicmodels)
library(RPostgreSQL)
library(DBI)
library(broom)
library(readxl)
theme_set(theme_light())
```


```{r}
drv <- dbDriver('PostgreSQL')
con <- dbConnect(drv, 
                 dbname="aact",
                 host="aact-db.ctti-clinicaltrials.org", 
                 port=5432,
                 user=readr::read_csv("id_pw.csv")$id, 
                 password=readr::read_csv("id_pw.csv")$pw
                 )

dbTables <- dbListTables(con)
```


## Notes about AACT (Source: https://aact.ctti-clinicaltrials.org/points_to_consider)
The AACT database is updated every night at midnight, so the information in AACT is one day behind that which appears in ClinicalTrials.gov

Tables with `MeSH terms` as a variable: intervention_browse, condition_browse, mesh_thesaurus.

In ClinicalTrials.gov, each trial has keywords that describe the trial. The ClinicalTrials.gov team assigns each trial two sets of MeSH terms. One set for the conditions studied by the trial and another for the set of interventions used in the trial. The XML file that can be downloaded for each trial contains these MeSH keywords. The XML file also has a comment that says: "the assignment of MeSH keywords is done by imperfect algorithm".

When data submitters provide information to ClinicalTrials.gov about a study, theyâ€™re encouraged to use Medical Subject Heading (MeSH) terminology for interventions, conditions, and keywords. The Browse_Conditions and Browse_Interventions tables contain MeSH terms generated by an algorithm run by NLM. The NLM algorithm is re-run nightly on all studies in the ClinicalTrials.gov database, and sources the most up-to-date information in the study record, the latest version of the algorithm, and the version of the MeSH thesaurus in use at that time.


Studies registered at ClinicalTrials.gov are identified by a unique identifier, the NCT_ID


## Explore MeSH terms in browse_conditions table
```{r}
# browse_conditions
browse_conditions <- tbl(con, "browse_conditions") %>% 
  collect()

```

There are duplicate nct_ids, but when you count by nct_id and mesh_term, there are NO duplicates. 

### Explore mesh_term inside browse_conditions
```{r}
browse_conditions %>% 
  count(mesh_term, sort = TRUE) %>% 
  head(20) %>% 
  mutate(mesh_term = fct_reorder(mesh_term, n)) %>% 
  ggplot(aes(mesh_term, n, fill = mesh_term)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(x = "MeSH Terms", y = "Counts") +
  ggtitle("Top 20 Most Occuring MeSH Terms in Conditions Table")
```

## LDA on mesh_term

https://www.tidytextmining.com/

Followed this tutorial by David Robinson and Julia Siege:
https://cran.r-project.org/web/packages/tidytext/vignettes/topic_modeling.html

```{r}
# Create counts dataset
mesh_term_counts <- browse_conditions %>% 
  count(nct_id, mesh_term, sort = TRUE) %>% 
  ungroup() 

# Get Document Term Matrix using cast_dtm
condition_dtm <- mesh_term_counts %>% 
  cast_dtm(nct_id, mesh_term, n)

# Use topicmodels package to create a four topic LDA model
topic_lda <- topicmodels::LDA(condition_dtm, k = 4, control = list(seed = 1234))

topic_lda_td <- tidy(topic_lda)

# Find top 5 terms within each topic:
top_mesh_terms <- topic_lda_td %>% 
  group_by(topic) %>% 
  top_n(5, beta) %>% 
  ungroup() %>% 
  arrange(topic, -beta)
```


```{r}
top_mesh_terms %>%
  mutate(term = reorder(term, beta)) %>% 
  ggplot(aes(term, beta, fill = term)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "MeSH",
       y = "Beta (Probability of MeSH being generated from topic)") +
  ggtitle("Distribution of MeSH for 4 Topics from LDA")
```

